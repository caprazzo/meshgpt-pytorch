{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install  -q git+https://github.com/MarcusLoppe/meshgpt-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'model_M0001'\n",
    "working_dir = f'{project_name}'\n",
    "models_dir = f'{working_dir}/models'\n",
    "dataset_dir = f'datasets/'\n",
    "model_name = f\"M0001_E36\"\n",
    "\n",
    "encoder_checkpoint = f'{models_dir}/2024-07-23-M0001-encoder-loss_0.170.pt'\n",
    "transformer_checkpoint = f'{models_dir}/mesh-transformer.ckpt.epoch_3_avg_loss_0.573.pt'\n",
    "dataset_path = f\"{dataset_dir}/objverse_shapenet_modelnet_max_250faces_186M_tokens_cpu.npz\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "from meshgpt_pytorch import (\n",
    "    MeshTransformerTrainer,\n",
    "    MeshAutoencoderTrainer,\n",
    "    MeshAutoencoder,\n",
    "    MeshTransformer\n",
    ")\n",
    "from meshgpt_pytorch.data import ( \n",
    "    derive_face_edges_from_faces\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 50.7M\n"
     ]
    }
   ],
   "source": [
    "# 16k 2 4\n",
    "autoencoder = MeshAutoencoder(     \n",
    "    decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,   \n",
    "    dim_codebook = 192,  \n",
    "    dim_area_embed = 16,\n",
    "    dim_coor_embed = 16, \n",
    "    dim_normal_embed = 16,\n",
    "    dim_angle_embed = 8,    \n",
    "    attn_decoder_depth  = 4,\n",
    "    attn_encoder_depth = 2\n",
    ").to(\"cpu\")\n",
    "\n",
    "total_params = sum(p.numel() for p in autoencoder.parameters()) \n",
    "total_params = f\"{total_params / 1000000:.1f}M\"\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "pkg = torch.load(encoder_checkpoint, map_location=torch.device('cpu'))\n",
    "autoencoder.load_state_dict(pkg['model'])\n",
    "for param in autoencoder.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder total parameters: 321.5M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc  \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()   \n",
    "# max_seq = max(len(d[\"faces\"]) for d in dataset if \"faces\" in d)  * (autoencoder.num_vertices_per_face * autoencoder.num_quantizers) \n",
    "# print(\"Max token sequence:\" , max_seq)  \n",
    "transformer = MeshTransformer(\n",
    "    autoencoder,\n",
    "    dim =768,\n",
    "    coarse_pre_gateloop_depth = 6,  \n",
    "    fine_pre_gateloop_depth= 4, \n",
    "    attn_depth = 24,  \n",
    "    attn_heads = 16,\n",
    "    dropout  = 0.0,\n",
    "    max_seq_len = 1500,\n",
    "    condition_on_text = True, \n",
    "    gateloop_use_heinsen = False,\n",
    "    text_condition_model_types = \"bge\", \n",
    "    text_condition_cond_drop_prob = 0.0, \n",
    ").to(\"cpu\") \n",
    "\n",
    "total_params = sum(p.numel() for p in transformer.decoder.parameters())\n",
    "total_params = f\"{total_params / 1000000:.1f}M\"\n",
    "print(f\"Decoder total parameters: {total_params}\")\n",
    "\n",
    "pkg = torch.load(transformer_checkpoint, map_location=torch.device('cpu')) \n",
    "transformer.load_state_dict(pkg['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and view mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using only text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from meshgpt_pytorch import mesh_render \n",
    "# from pathlib import Path\n",
    "# import datetime\n",
    " \n",
    "# folder = f'{working_dir}/renders'\n",
    "# obj_file_path = Path(folder)\n",
    "# obj_file_path.mkdir(exist_ok = True, parents = True)  \n",
    "\n",
    "# text_coords = [] \n",
    "# text_coords.append(transformer.generate(texts = [\"plate\"],  temperature = 0.0))   \n",
    "\n",
    "# current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# results_filename = f\"{current_datetime}_{model_name}_test_results.obj\"\n",
    "# mesh_render.save_rendering(f'{folder}/{results_filename}', text_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sofa couch lounge love seat loveseat tete-a-tete vis-a-vis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                      | 0/1500 [00:00<?, ?it/s]/Users/matteo/Desktop/Teo/Projects/meshgpt-pytorch/.venv/lib/python3.12/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.\n",
      "  warnings.warn(\n",
      " 46%|███████████████████████████████████████████████████████████████████████████████▊                                                                                            | 696/1500 [00:14<00:16, 47.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rectangular table coffee table cocktail table table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 1116/1500 [00:22<00:07, 48.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 936/1500 [00:21<00:13, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 912/1500 [00:20<00:13, 44.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating bookshelf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 1068/1500 [00:23<00:09, 45.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sofa couch lounge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████████▋                                                                                                                                            | 276/1500 [00:05<00:26, 46.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tv_stand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 876/1500 [00:18<00:13, 47.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating My Sculpture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████████████████████▎                                                                                                                                  | 360/1500 [00:07<00:24, 47.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 912/1500 [00:19<00:12, 46.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Abstract Sculpture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████████▏                                                                                                                                      | 324/1500 [00:06<00:24, 47.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Sword\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 1020/1500 [00:22<00:10, 46.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████████                                                                                                                                           | 288/1500 [00:06<00:25, 46.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tv table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████████████████████████████████████▎                                                                                                 | 648/1500 [00:13<00:17, 48.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating office table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 984/1500 [00:20<00:10, 47.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating high chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████████████████████████████████████████                                                                                                          | 576/1500 [00:11<00:19, 48.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating glass table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████████████████████████▊                                                                                                       | 600/1500 [00:13<00:20, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating designer sloped chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████████████████████▌                                                                                                                          | 432/1500 [00:09<00:22, 47.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating designer chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████████████████████████████████████▏                                                                                                                | 516/1500 [00:10<00:20, 49.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating corner table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 936/1500 [00:20<00:12, 45.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating circle chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 984/1500 [00:21<00:11, 45.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating bar chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████████████████████████████████████████▉                                                                                                   | 636/1500 [00:14<00:19, 44.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating shoe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████████████████████▌                                                                                                                          | 432/1500 [00:09<00:23, 45.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                 | 792/1500 [00:16<00:15, 46.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                   | 1188/1500 [00:27<00:07, 43.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 804/1500 [00:18<00:15, 44.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████████████████████████████████████████▊                                                                                            | 696/1500 [00:14<00:17, 46.71it/s]\n",
      "/Users/matteo/Desktop/Teo/Projects/meshgpt-pytorch/meshgpt_pytorch/mesh_render.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  normal = normal / np.linalg.norm(normal)\n",
      "/Users/matteo/Desktop/Teo/Projects/meshgpt-pytorch/meshgpt_pytorch/mesh_render.py:19: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  angle_rad = np.arccos(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))\n",
      "/Users/matteo/Desktop/Teo/Projects/meshgpt-pytorch/meshgpt_pytorch/mesh_render.py:19: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle_rad = np.arccos(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Save_rendering] Saved at model_M0001/renders/2024-08-03_21-41-37_M0001_E36_temp0.0_test_results.obj\n"
     ]
    }
   ],
   "source": [
    "from meshgpt_pytorch import mesh_render \n",
    "from pathlib import Path\n",
    "import datetime\n",
    " \n",
    "folder = f'{working_dir}/renders'\n",
    "obj_file_path = Path(folder)\n",
    "obj_file_path.mkdir(exist_ok = True, parents = True)  \n",
    "\n",
    "\n",
    "query = [\n",
    "    # long labels\n",
    "    \"sofa couch lounge love seat loveseat tete-a-tete vis-a-vis\",\n",
    "    \"rectangular table coffee table cocktail table table\",\n",
    "    # top labels by frequency\n",
    "    'chair', 'table', 'bookshelf', 'sofa couch lounge', 'tv_stand', 'My Sculpture', 'Table', 'Abstract Sculpture', 'Sword', 'cone',\n",
    "    # made up labels\n",
    "    'tv table', 'office table', 'high chair', 'glass table',\n",
    "    'designer sloped chair', 'designer chair', 'corner table', 'circle chair', 'bar chair',\n",
    "    'shoe', 'cup', 'plate', 'vase', 'person'\n",
    "]\n",
    "\n",
    "temperature = 0.0\n",
    "    \n",
    "text_coords = [] \n",
    "for text in (query):\n",
    "    print(f\"Generating {text}\") \n",
    "    text_coords.append(transformer.generate(texts = [text],  temperature = temperature))   \n",
    "\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "results_filename = f\"{current_datetime}_{model_name}_temp{temperature:.1f}_test_results.obj\"\n",
    "mesh_render.save_rendering(f'{folder}/{results_filename}', text_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text + prompt of tokens**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt with 10% of codes/tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MeshDataset] Loaded 218835 entries\n",
      "[MeshDataset] Created from 218835 entries\n",
      "Generating sofa couch lounge love seat loveseat tete-a-tete vis-a-vis with 59 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 1069/1441 [00:24<00:08, 43.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rectangular table coffee table cocktail table table with 49 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 1199/1451 [00:29<00:06, 40.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating chair with 43 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 917/1457 [00:22<00:12, 41.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating table with 18 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 1062/1482 [00:24<00:09, 44.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating bookshelf with 27 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                | 921/1473 [00:21<00:12, 43.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sofa couch lounge with 30 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 930/1470 [00:21<00:12, 43.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tv_stand with 51 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 1053/1449 [00:25<00:09, 40.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating My Sculpture with 39 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 891/1461 [30:42<19:38,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Table with 36 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████████████████████████████████████▉                                                                                                    | 612/1464 [33:15<46:17,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Abstract Sculpture with 21 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████████                                                                                                                                      | 327/1479 [15:39<55:09,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Sword with 75 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 813/1425 [23:44<17:52,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cone with 43 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████████████▉                                                                                                                                                       | 162/1457 [15:45<5:49:15, 16.18s/it]"
     ]
    }
   ],
   "source": [
    "# To extract labels from dataset\n",
    "from meshgpt_pytorch import MeshDataset \n",
    "dataset = MeshDataset.load(dataset_path)#, map_location=torch.device('cpu')) \n",
    "labels = query # list(set(item[\"texts\"] for item in dataset.data))\n",
    "\n",
    "from pathlib import Path \n",
    "from meshgpt_pytorch import mesh_render \n",
    "folder = f\"{working_dir}/renders/text+codes\"\n",
    "obj_file_path = Path(folder)\n",
    "obj_file_path.mkdir(exist_ok = True, parents = True)  \n",
    "\n",
    "token_length_procent = 0.10 \n",
    "codes = []\n",
    "texts = []\n",
    "for label in query:\n",
    "    for item in dataset.data: \n",
    "        if item['texts'] == label:\n",
    "            tokens = autoencoder.tokenize(\n",
    "                vertices = item['vertices'],\n",
    "                faces = item['faces'],\n",
    "                face_edges = item['face_edges']\n",
    "            ) \n",
    "            num_tokens = int(tokens.shape[0] * token_length_procent)  \n",
    "            texts.append(item['texts']) \n",
    "            codes.append(tokens.flatten()[:num_tokens].unsqueeze(0))  \n",
    "            break\n",
    "        \n",
    "coords = []  \n",
    "for text, prompt in zip(texts, codes): \n",
    "    print(f\"Generating {text} with {prompt.shape[1]} tokens\") \n",
    "    coords.append(transformer.generate(texts = [text],  prompt = prompt, temperature = 0) )    \n",
    "      \n",
    "mesh_render.save_rendering(f'{folder}/text+prompt_{token_length_procent*100}_{model_name}.obj', coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt with 0% to 80% of tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from meshgpt_pytorch import mesh_render \n",
    " \n",
    "# folder = working_dir / f'renders/text+codes_rows'\n",
    "# obj_file_path = Path(folder)\n",
    "# obj_file_path.mkdir(exist_ok = True, parents = True)   \n",
    "\n",
    "# mesh_rows = []\n",
    "# for token_length_procent in np.arange(0, 0.8, 0.1):\n",
    "#     codes = []\n",
    "#     texts = []\n",
    "#     for label in labels:\n",
    "#         for item in dataset.data: \n",
    "#             if item['texts'] == label:\n",
    "#                 tokens = autoencoder.tokenize(\n",
    "#                     vertices = item['vertices'],\n",
    "#                     faces = item['faces'],\n",
    "#                     face_edges = item['face_edges']\n",
    "#                 ) \n",
    "#                 num_tokens = int(tokens.shape[0] * token_length_procent) \n",
    "                \n",
    "#                 texts.append(item['texts']) \n",
    "#                 codes.append(tokens.flatten()[:num_tokens].unsqueeze(0))  \n",
    "#                 break\n",
    "            \n",
    "#     coords = []   \n",
    "#     for text, prompt in zip(texts, codes):  \n",
    "#         print(f\"Generating {text} with {prompt.shape[1]} tokens\") \n",
    "#         coords.append(transformer.generate(texts = [text],  prompt = prompt, temperature = 0)) \n",
    "         \n",
    "#     mesh_rows.append(coords)  \n",
    "    \n",
    "# mesh_render.save_rendering(f'{folder}/all.obj', mesh_rows)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just some testing for text embedding similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# texts = list(labels)\n",
    "# vectors = [transformer.conditioner.text_models[0].embed_text([text], return_text_encodings = False).cpu().flatten() for text in texts]\n",
    " \n",
    "# max_label_length = max(len(text) for text in texts)\n",
    " \n",
    "# # Print the table header\n",
    "# print(f\"{'Text':<{max_label_length}} |\", end=\" \")\n",
    "# for text in texts:\n",
    "#     print(f\"{text:<{max_label_length}} |\", end=\" \")\n",
    "# print()\n",
    "\n",
    "# # Print the similarity matrix as a table with fixed-length columns\n",
    "# for i in range(len(texts)):\n",
    "#     print(f\"{texts[i]:<{max_label_length}} |\", end=\" \")\n",
    "#     for j in range(len(texts)):\n",
    "#         # Encode the texts and calculate cosine similarity manually\n",
    "#         vector_i = vectors[i]\n",
    "#         vector_j = vectors[j]\n",
    "        \n",
    "#         dot_product = torch.sum(vector_i * vector_j)\n",
    "#         norm_vector1 = torch.norm(vector_i)\n",
    "#         norm_vector2 = torch.norm(vector_j)\n",
    "#         similarity_score = dot_product / (norm_vector1 * norm_vector2)\n",
    "        \n",
    "#         # Print with fixed-length columns\n",
    "#         print(f\"{similarity_score.item():<{max_label_length}.4f} |\", end=\" \")\n",
    "#     print()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
